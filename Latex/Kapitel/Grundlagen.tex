%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Ungleichungsnebenbedingungen}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:Ungleichungsnebenbedingungen}
Wie schon angeführt, ist ein Vorteil des MPC Ansatzes die direkte Berücksichtigung von Nebenbedingungen. Das gilt sowohl für Gleichungsnebenbedingungen als auch Ungleichungsnebenbedingungen.  Bei dem später beschriebenen Algorithmus werden ausschließlich die zur Prädiktion nötigen linearen Dynamiken eines zu regelnden Systems als Gleichungsnebenbedingungen der Form
\begin{equation*}
 x_{k+1} = Ax_{k} + Bu_{k}
\end{equation*}
berücksichtigt.\\
Zusätzlich zu der Einhaltung der Systemdynamik wird allgemein gefordert, dass sowohl Zustände als auch Stellgrößen aus erlaubten Mengen von Werten
\begin{align*}
  &\boldsymbol{x}(k) \in \mathcal{X}\subset\mathbb{R}^n\\
  &\boldsymbol{u}(k) \in \mathcal{U}\subset\mathbb{R}^m
\end{align*}
stammt (\cite{mayne2000constrained}). Dieses wird, je nach Eigenschaften von $\mathcal{X}$ und $\mathcal{U}$, mit Hilfe von Ungleichungsnebenbedingungen in verschiedenen Formen, die im folgenden Abschnitt kurz erläutert werden, sichergestellt. Begonnen wird mit einfachen Ungleichungsnebenbedingungen in linearer Form, es folgen spezielle Formen nichtlienarer Ungleichungsnebenbedingungen, die häufig Anwendung finden.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Lineare Ungleichungsnebenbedingungen}%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:LineareUngleichungsnebenbedingungen}
In Regelungsproblemen treten häufig Fälle auf, in denen für einzelne oder alle Zustände beispielsweise aus Sicherheitsgründen bestimmte Werte nicht unter- bzw. überschritten werden dürfen. Änliches git auch Systemeingänge bei denen aus beispielsweise technischen Gründen nur nur Werte aus einem bekannten Intervall auf das System gegeben werden können. Solche einfachen Zustandsbeschränkungen der Form
\begin{align*}
 x_{min}\leq &x(k)\leq x_{max}, \quad k = 0, 1, \dots\\
 u_{min}\leq &u(k)\leq u_{max}, \quad k = 0, 1, \dots
\end{align*}
werden auch als box constraints bezeichnet (\cite{BOY10}). Dabei gilt $x_{min}, x_{max} \in \mathbb{R}^n$ und $u_{min}, u_{max} \in \mathbb{R}^m$.\\
Mixed constraints guck mal muao mpc wegen beschreibung.\\
Alle so beschriebenen linearen Ungleichungsnebenbedingungen lassen sich als ein System von $l$ linearen Ungleichungen
\begin{equation}
 \label{eq:linequ}
 F_{x}x(k) + F_{u}u(k) \leq f, \quad k = 0, 1, \dots
\end{equation}
mit $F_{x}\in \mathbb{R}^{l\times n}, F_{u}\in \mathbb{R}^{l\times m}$ und $f\in \mathbb{R}^{l}$ zusammenfassen.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quadratic Constraints}%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:QuadraticConstraints}
Was genau, wofür QC?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Second Order Cone Constraints}%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:SecondOrderConeConstraints}
Was genau, wofür SOCC?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Soft Constraints}%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:SoftConstraints}
Manchmal liegen die Lösungen der Optimierungsprobleme an Rande der feasible Regionen und so kann es dazu kommen, dass durch Störungen auf das System, Lösungsvektoren nicht mehr feasibl sind. Da es besser ist, den Algorithmus nicht abzubrechen sondern mit einer nicht erlaubten Punkt weiter zu arbeiten, gibt es die Möglichkeit Soft Constraints einzuführen. Dieses weichen wie der Name schon sagt, die harten Ungleichungsnebenbedingungen auf, sodass diese Verletzt werden können. diese Verletzung geht als zusätzliche Strafe mit in die Kostenfunktionen ein. Bei richtiger Wichtung der Verletzung, sorgt er Optimierungsalgorithmus dafür, dass diese Grenzen nur verletzt werden, wenn keiner Punkt mehr feasibl ist.\\
Im folgenden Abschnitt werden 2 Möglichkeiten erlärt, solche Soft Constraints einzuführen, die ich im Zuge meiner Masterarbeit bzgl der auswirkung des nichteinhaltens der exact penalty function untersuche und vergleiche.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Soft Constraints mittels Einführung zusätzlicher Slackvariablen}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:SoftWithSlack}
Die übliche Methode, weil auch die kofortabelste, statt harten Ungleichungsnebenbedingungen weichen Ungleichungsnebenbedingungen (oder Soft Constraints) zu verwenden, ist die Einführung von Schlupfvariablen (slack variables) (\cite{richards2013fast}). Das lässt sich unkompliziert durch die Erweiterung des Stellgrößen Vektors um eine zusätzliche Variable $s(k)$ ohne phsikalische Bedeutung zu $\begin{bmatrix}u^{T}(k)& s(k)\end{bmatrix}^T$ für jeden Zeitschritt $k$ durchführen. Analog zu Ungleichung \ref{eq:linequ} lassen sich dann die soft constriants als
\begin{equation}
 \label{eq:softinequ}
\begin{bmatrix}
\tilde{F}_{x}\\ 0
\end{bmatrix}x(k) + \begin{bmatrix}
\tilde{F}_{u} & -1\\ 0& -1 
\end{bmatrix}\begin{pmatrix}u(k)\\s(k)\end{pmatrix} \leq \begin{bmatrix}\tilde{f}\\0\end{bmatrix}, \quad k = 0, 1, \dots
\end{equation}
formulieren. $s(k)$ ist dabei die maximale Verletzung der der Ungleichungsnebenbedingungen im $k$ten Zeitschritt, $s(k) = 0$ sofern alle Ungleichungsnebenbedingungen erfüllt sind und wird in der Kostenfunktion entsprechend bestraft, sodass $s(k) \neq 0$ nur dann, wenn andernfalls kein valider Schritt möglich ist. Es ist zu erwähnen dass zur Berrücksichtigung der Soft Constraints in dieser Formulierung keine besondere Berücksichtigung im Algorithmus vorgesehen sein muss. Lediglich die Formulierung der Matrizen und Dimensionen für das zu lösende Optimierungsproblem müssen angepasst werden.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Soft Constraints mittels Einführung eines Strafterms in Form der Kreisselmeier-Steinhauser Funktion}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:SoftWithKSF}
In \cite{richards2013fast} wird eine weitere Möglichkeit vorgeschlagen, um lineare Ungleichungsnebenbedingungen als soft constraints zu nutzen. Der Artikel ist darauf fokussiert die soft constraints zugeschnitten zu dem Algorithmus aus \cite{BOY10} einzuführen. Dazu wird die sogenannte Kreisselmeier-Steinhauser (KS) Funktion
\begin{equation*}
 KS'(g(x)) = \frac{1}{\rho}\log \left[ \sum_{j}\exp (\rho g_{j}(x)) \right ]
\end{equation*}
nach \cite{kreisselmeier1979systematic} [darf ich das?] genutzt. Um Probleme mit zu starkem exponentiellen Wachstum zu vermeiden nimmt man genauer gesagt eine equivalente Form der KS Funktion, bei der diese Probleme nicht auftreten:
\begin{equation}
 KS(g(x)) = g_{max}(x)+\frac{1}{\rho}\log \left[ \sum_{j}\exp (\rho (g_{j}(x)-g_{max(x)})) \right ].
\end{equation}
Ähnlich wie bei die log barrier den Übergang von feasibl zu infeasibl annähert, dient die KS Funktion dazu, die Nichtkontinuität des Gradienten zu durch eine kontinuierliche Funktion zu approximieren. Analog zu der Reduzierung von $\kappa$ führt eine Erhöhung von $\rho$ dazu, dass man sich der exakten Funktion nähert.\\
Um mit der KS Funktion soft constraints in den Algorithmus von Boyd zu integrieren sind folgende Schritte notwendig. Soft constraints analog zu \ref{eq:IEQ} formulieren
\begin{equation*}
 \tilde{P}z \leq\tilde{h}.
\end{equation*}
Sodass der Strafterm
\begin{equation*}
 \sum_i \max\{0, \tilde{p}_i^T z- \tilde{h}_i\}
\end{equation*}
mit Hilfe der KS Fnuktion als 
\begin{equation*}
 \theta(z)=\sum_i \frac{1}{\rho}\log \left[1 + \exp (\rho (\tilde{p}_i^T z- \tilde{h}_i)) \right ]
\end{equation*}
formuliert werden kann.\\
\begin{align*}
 e_i^+\\
 e_i^-
\end{align*}
für Gradient der Straffunktion
\begin{equation}
 \nabla
\end{equation}
mit
\begin{equation}
 \tilde{d}
\end{equation}
Und die Hessian
\begin{equation}
 \nabla^2
\end{equation}
mit
\begin{equation}
 \hat{d}
\end{equation}
$\Phi$ und $r_d$ anpassen.\\
Auf Struktur geachtet, die die vorher ausgenutzte Struktur nicht verändert.
\abk{KS}{Kreisselmeier-Steinhauser}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Exact Penalty Functions}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:ExactPenaltyFunctions}
Siehe \cite{kerrigan2000soft}\\
In der ersten Variante der Verwendung von soft constraints ist es möglich mit der Richtigen Wichtung der Strafe für die Verletzung der Ungleichungsnebenbedingungen zu garantieren, dass bei ausreichend genauer Lösung des Optimierungsproblems auch die exakte Lösung gefunden wird, sofern diese feasibl ist und wirklich nur bei keinen feasiblen Lösungen Verletzungen zugelassen werden. Hier wird grob angerissen, was dazu nötig ist, um eine exact penalty function zu haben. Im Rahmen dieser Masterarbeit soll noch untersucht werden, ob der Verlust der exact penalty function Garantie bei der KS Funktion Variante in kritischen und unkritischen Fällen mit Nachteilen zu rechnen ist.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Polynimial Chaos Expansion}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:PCE}
Wie bekomme ich aus einem normalen QP ein PCE?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Weitere Mathematische Grundlagen}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:MathematischeGrundlagen}
Was muss man wissen, um spätere Umstellungen und Ableitungen und Berechnungen zu verstehen?
